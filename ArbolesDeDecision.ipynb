{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArbolesDeDecision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO9VlgsAGAFCNczOgsOYu5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdambrosioz/aa_2021/blob/main/ArbolesDeDecision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZZUpv6uc2Pv"
      },
      "source": [
        "# **Métodos basados en árboles**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQtJZbqSbsmS"
      },
      "source": [
        "# Importamos paquetes necesarios\n",
        "import sklearn as s\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-6Y50oDdOJb"
      },
      "source": [
        "person_df = pd.read_csv('https://raw.githubusercontent.com/rdambrosioz/aa_2021/main/500_Person_Gender_Height_Weight_Index.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "B_OYNoLGe0oR",
        "outputId": "83f0edf2-2eef-41d4-b0df-239e584162f7"
      },
      "source": [
        "features = person_df.columns[0:-1]\n",
        "person_df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>174</td>\n",
              "      <td>96</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>189</td>\n",
              "      <td>87</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>185</td>\n",
              "      <td>110</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>195</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>149</td>\n",
              "      <td>61</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>Female</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Female</td>\n",
              "      <td>184</td>\n",
              "      <td>121</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Female</td>\n",
              "      <td>141</td>\n",
              "      <td>136</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Male</td>\n",
              "      <td>150</td>\n",
              "      <td>95</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Male</td>\n",
              "      <td>173</td>\n",
              "      <td>131</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender  Height  Weight  Index\n",
              "0      Male     174      96      4\n",
              "1      Male     189      87      2\n",
              "2    Female     185     110      4\n",
              "3    Female     195     104      3\n",
              "4      Male     149      61      3\n",
              "..      ...     ...     ...    ...\n",
              "495  Female     150     153      5\n",
              "496  Female     184     121      4\n",
              "497  Female     141     136      5\n",
              "498    Male     150      95      5\n",
              "499    Male     173     131      5\n",
              "\n",
              "[500 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "nq8IujFZfMjd",
        "outputId": "fc34ed80-5a68-411a-b8f2-b2872df6d9fb"
      },
      "source": [
        "person_df.dtypes, person_df['Index'].describe(), person_df['Index'].hist()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Gender    object\n",
              " Height     int64\n",
              " Weight     int64\n",
              " Index      int64\n",
              " dtype: object, count    500.000000\n",
              " mean       3.748000\n",
              " std        1.355053\n",
              " min        0.000000\n",
              " 25%        3.000000\n",
              " 50%        4.000000\n",
              " 75%        5.000000\n",
              " max        5.000000\n",
              " Name: Index, dtype: float64, <matplotlib.axes._subplots.AxesSubplot at 0x7f7b5908e550>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGOtso41hW1t"
      },
      "source": [
        "Imaginamos que queremos predecir si la persona es, o no, obesa. Según la descripción del dataset, las personas con indice de 4 o 5 son obesas, por lo que podríamos crear una variable que refleje esto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA4adRxJhh5b"
      },
      "source": [
        "person_df['obese'] = (person_df.Index >= 4).astype('int').astype('str')\n",
        "person_df.drop('Index', axis = 1, inplace = True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX1F0YjciW6H"
      },
      "source": [
        "Eliminamos la columna Index, en su lugar creamos la columna obese, con un 1 si el index era de 4 o 5, 0 en caso contrario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "gtw4GnaPiMX1",
        "outputId": "4a27a630-694f-4869-801e-e6f6909dd008"
      },
      "source": [
        "person_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>obese</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Male</td>\n",
              "      <td>174</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Male</td>\n",
              "      <td>189</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Female</td>\n",
              "      <td>185</td>\n",
              "      <td>110</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Female</td>\n",
              "      <td>195</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>149</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>Female</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>Female</td>\n",
              "      <td>184</td>\n",
              "      <td>121</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>Female</td>\n",
              "      <td>141</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>Male</td>\n",
              "      <td>150</td>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Male</td>\n",
              "      <td>173</td>\n",
              "      <td>131</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Gender  Height  Weight obese\n",
              "0      Male     174      96     1\n",
              "1      Male     189      87     0\n",
              "2    Female     185     110     1\n",
              "3    Female     195     104     0\n",
              "4      Male     149      61     0\n",
              "..      ...     ...     ...   ...\n",
              "495  Female     150     153     1\n",
              "496  Female     184     121     1\n",
              "497  Female     141     136     1\n",
              "498    Male     150      95     1\n",
              "499    Male     173     131     1\n",
              "\n",
              "[500 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a58l45oWjlpp"
      },
      "source": [
        "En ese caso, un árbol de decisión nos diría distintas reglas, como por ejemplo, que si el peso de la persona es superior a 100kg, lo más probable es que esa persona sea obesa. Sin embargo, ese corte no será preciso: habrá personas que pesen 100kg que no sean obesas. Así pues, el árbol de decisión sigue creando más ramas que generan nuevas condiciones para ir “afinando” nuestras predicciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDtFJoOIkJ3j"
      },
      "source": [
        "### Indice de Gini y la Entropía\n",
        "\n",
        "Como en todos los algoritmos, la función de coste es la base del algoritmo. En el caso de los árboles de decisión, existen dos principales funciones de coste: el índice de Gini y la entropía."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbysEotUkUKm",
        "outputId": "826496c1-9b03-4e71-ebfb-a457f6d71f14"
      },
      "source": [
        "# Calculo del indice de Gini\n",
        "\n",
        "def gini_impurity(y):\n",
        "  \n",
        "  if isinstance(y, pd.Series):\n",
        "    p = y.value_counts()/y.shape[0]\n",
        "    gini = 1-np.sum(p**2)\n",
        "    return(gini)\n",
        "    \n",
        "  else:\n",
        "    raise('Object must be a Pandas Series.')\n",
        "\n",
        "gini_impurity(person_df.Gender)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4998"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCBWbK0SlO3R"
      },
      "source": [
        "El rango del indice de Gini va de 0 a 1.\n",
        "\n",
        "Como vemos, el índice de Gini para la variable Género es muy cercano al 0,5. Esto indica que la variable Género es muy impura, es decir, que los resultados del corte no son buenos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dincOhljlUZY",
        "outputId": "87df7a9d-504a-43e8-c9cf-4c2d05b6467f"
      },
      "source": [
        "def entropy(y):\n",
        "  \n",
        "  if isinstance(y, pd.Series):\n",
        "    a = y.value_counts()/y.shape[0]\n",
        "    entropy = np.sum(-a*np.log2(a+1e-9))\n",
        "    return(entropy)\n",
        "\n",
        "  else:\n",
        "    raise('Object must be a Pandas Series.')\n",
        "\n",
        "entropy(person_df.Gender)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9997114388674198"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg55Dlj8mVHa"
      },
      "source": [
        "El rango de la entropia va de 0 a 1. Los valores cercanos a cero son menos impuros que aquellos que se acercan al 1.\n",
        "\n",
        "Como vemos, nos da un valor muy cercano al 1, lo cual denota una impureza similar a lo que indice la impureza de Gini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIiTlucPnccP"
      },
      "source": [
        "### Cómo elegir los cortes para nuestro árbol de decisión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDzD8_6Zn4FU"
      },
      "source": [
        "Como hemos visto, los cortes se comparan mediante la impureza. Por tanto, nos interesa comparar aquellos cortes que menor impureza generan. Para ello, se utiliza el Information Gain. Esta métrica indica la mejora al hacer diferentes particiones y se suele utilizar con la entropía.\n",
        "\n",
        "El cálculo del Information Gain dependerá de si se trata de un árbol de decisión de clasificación o de regresión. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Aw4FcRn5tP"
      },
      "source": [
        "def variance(y):\n",
        "  \n",
        "  if(len(y) == 1):\n",
        "    return 0\n",
        "  else:\n",
        "    return y.var()\n",
        "\n",
        "def information_gain(y, mask, func=entropy):\n",
        "  # Mask: split choice\n",
        "  # func: function to be used to calculate Information Gain in case os classification.\n",
        "  \n",
        "  a = sum(mask)\n",
        "  b = mask.shape[0] - a\n",
        "  \n",
        "  if(a == 0 or b ==0): \n",
        "    ig = 0\n",
        "  \n",
        "  else:\n",
        "    if y.dtypes != 'O':\n",
        "      ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
        "    else:\n",
        "      ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
        "  \n",
        "  return ig"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4cCmMq-ofBp",
        "outputId": "92e69310-a193-4d61-fbd0-0fd1d09af7d2"
      },
      "source": [
        "information_gain(person_df['obese'], person_df['Gender'] == 'Male')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005506911187600494"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmtEmF8WpCSN"
      },
      "source": [
        "¿Cómo elegimos cuál es el mejor split en las variables numéricas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSfDw40dpH44"
      },
      "source": [
        "### Cómo calcular el mejor split para una variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O8GSTHlpYo_"
      },
      "source": [
        "Para calcular el mejor split de una variable numérica, lo primero se deben obtener todos posibles valores que está tomando la variable. Una vez tenemos las opciones, para cada opción calcularemos el Information Gain usando como filtro si el valor es inferior a ese valor.\n",
        "\n",
        "En caso de que contemos con variables categóricas, la idea es la misma, solo que en este caso deberemos calcular el Information Gain para todas las combinaciones posibles de esa variable, excluyendo la opción que incluye a todas las opciones.\n",
        "\n",
        "Así pues, una vez tengamos todos los splits, nos quedaremos con aquel split que genere un mayor Information Gain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhMwPxK_o3Xa",
        "outputId": "8c1aa471-15f2-4b00-c966-da8f63340d0f"
      },
      "source": [
        "import itertools\n",
        "\n",
        "def categorical_options(a):\n",
        "  \n",
        "  a = a.unique()\n",
        "  opciones = []\n",
        "  \n",
        "  for L in range(0, len(a)+1):\n",
        "      for subset in itertools.combinations(a, L):\n",
        "          subset = list(subset)\n",
        "          opciones.append(subset)\n",
        "\n",
        "  return opciones[1:-1]\n",
        "\n",
        "def max_information_gain_split(x, y, func=entropy):\n",
        "\n",
        "  split_value = []\n",
        "  ig = [] \n",
        "\n",
        "  numeric_variable = True if x.dtypes != 'O' else False\n",
        "\n",
        "  # Create options according to variable type\n",
        "  if numeric_variable:\n",
        "    options = x.sort_values().unique()[1:]\n",
        "  else: \n",
        "    options = categorical_options(x)\n",
        "\n",
        "  # Calculate ig for all values\n",
        "  for val in options:\n",
        "    mask =   x < val if numeric_variable else x.isin(val)\n",
        "    val_ig = information_gain(y, mask, func)\n",
        "    # Append results\n",
        "    ig.append(val_ig)\n",
        "    split_value.append(val)\n",
        "\n",
        "  # Check if there are more than 1 results if not, return False\n",
        "  if len(ig) == 0:\n",
        "    return(None,None,None, False)\n",
        "\n",
        "  else:\n",
        "  # Get results with highest IG\n",
        "    best_ig = max(ig)\n",
        "    best_ig_index = ig.index(best_ig)\n",
        "    best_split = split_value[best_ig_index]\n",
        "    return(best_ig,best_split,numeric_variable, True)\n",
        "\n",
        "\n",
        "weight_ig, weight_slpit, _, _ = max_information_gain_split(person_df['Weight'], person_df['obese'],)  \n",
        "\n",
        "\n",
        "print(\n",
        "  \"El mejor split para Weight es cuando la variable es inferior a \",\n",
        "  weight_slpit,\"\\nEl Information Gain para ese corte es:\", weight_ig\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El mejor split para Weight es cuando la variable es inferior a  103 \n",
            "El Information Gain para ese corte es: 0.3824541370911895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uItKtLv7qMEL"
      },
      "source": [
        "### Cómo elegir el mejor split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn7t6Q6KqOCK"
      },
      "source": [
        "Como he comentado previamente, el mejor split será aquel que genere un Information Gain más alto. Para conocerlo, simplemente tendremos que calcular el Information Gain para cada una de las variables predictoras del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "CxLw28i7qVJl",
        "outputId": "499cce7b-ab46-431d-cb5c-64941652f1eb"
      },
      "source": [
        "person_df.drop('obese', axis= 1).apply(max_information_gain_split, y = person_df['obese'])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000550691</td>\n",
              "      <td>0.0647483</td>\n",
              "      <td>0.382454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Male]</td>\n",
              "      <td>174</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Gender     Height    Weight\n",
              "0  0.000550691  0.0647483  0.382454\n",
              "1       [Male]        174       103\n",
              "2        False       True      True\n",
              "3         True       True      True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrvvF_3iqkrM"
      },
      "source": [
        "Como vemos, la variable con mayor Information Gain es Weight. Por tanto, será la variable que utilicemos primero para hacer el split. Además, tenemos también el valor sobre el cual se debe realizar el split: 103."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY5IMXdwqtBp"
      },
      "source": [
        "### Cómo entrenar un árbol de decisión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pmE2F_8qmFf"
      },
      "source": [
        "def get_best_split(y, data):\n",
        "  \n",
        "  # Dado un df, selecciona el mejor splin posible y retorna la variable, el valor, el tipo\n",
        "  # de variable y el IG\n",
        "  # y: nombre de la variable\n",
        "  # data: dataframe\n",
        "  \n",
        "  masks = person_df.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
        "  if sum(masks.loc[3,:]) == 0:\n",
        "    return(None, None, None, None)\n",
        "\n",
        "  else:\n",
        "    # Obtenemos los masks que puede ser splitteados\n",
        "    masks = masks.loc[:,masks.loc[3,:]]\n",
        "\n",
        "    split_variable = max(masks) # Obtenemos el que tiene mayor IG\n",
        "    split_value = masks[split_variable][1] \n",
        "    split_ig = masks[split_variable][0]\n",
        "    split_numeric = masks[split_variable][2]\n",
        "\n",
        "    return(split_variable, split_value, split_ig, split_numeric)\n",
        "\n",
        "\n",
        "def make_split(variable, value, data, is_numeric):\n",
        "  \n",
        "  # Dado un dataframe y una condicion de split, hacemos el split.\n",
        "  # variable: variable con la cual hacemos el split\n",
        "  # value: valor de la variable para hacer el split\n",
        "  # data: dataframe a ser spliteado\n",
        "  # is_numeric: boolean si la variable a ser spliteado es numerica o no\n",
        "  \n",
        "  if is_numeric:\n",
        "    data_1 = person_df[person_df[variable] < value]\n",
        "    data_2 = person_df[(person_df[variable] < value) == False]\n",
        "\n",
        "  else:\n",
        "    data_1 = data[person_df[variable].isin(value)]\n",
        "    data_2 = data[(person_df[variable].isin(value)) == False]\n",
        "\n",
        "  return(data_1,data_2)\n",
        "\n",
        "def make_prediction(data, target_factor):\n",
        "  # Dada la variable objetivo, hacemos la prediccion\n",
        "\n",
        "  if target_factor:\n",
        "    pred = person_df.value_counts().idxmax()\n",
        "  else:\n",
        "    pred = person_df.mean()\n",
        "\n",
        "  return pred"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyA2CI4EtmmW"
      },
      "source": [
        "Hiperparamtros importantes a tener en cuenta:\n",
        " \n",
        "\n",
        "1. max_depth: profundidad máxima del árbol. Si lo fijamos en None, el árbol crecerá hasta que todas las hojas sean puras o se haya alcanzado el hiperparámetro min_samples_split.\n",
        "2. in_samples_split: indica el número mínimo de observaciones que debe tener una hoja para seguir creando nuevos nodos.\n",
        "3. min_information_gain: la cantidad mínima que debe incrementar el Information Gain para que el árbol siga creciendo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExhBElPZuIW1"
      },
      "source": [
        "### Entrenando nuestro árbol de decisión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILhleNYsuJ6-",
        "outputId": "7a868573-9861-40b4-d6eb-7dc021f0d849"
      },
      "source": [
        "def train_tree(data, y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
        "  # Entrena un decision tree\n",
        "  # data: dataframe\n",
        "  # y: nombre de la variable objetivo\n",
        "  # target_factor: boolean para saber si la variable objetivo es numerica o no  \n",
        "\n",
        "  if counter==0:\n",
        "    types = data.dtypes\n",
        "    check_columns = types[types == \"object\"].index\n",
        "    for column in check_columns:\n",
        "      var_length = len(data[column].value_counts()) \n",
        "      if var_length > max_categories:\n",
        "        raise ValueError('The variable ' + column + ' has '+ str(var_length) + ' unique values, which is more than the accepted ones: ' +  str(max_categories))\n",
        "\n",
        "  # Check for depth conditions\n",
        "  if max_depth == None:\n",
        "    depth_cond = True\n",
        "\n",
        "  else:\n",
        "    if counter < max_depth:\n",
        "      depth_cond = True\n",
        "\n",
        "    else:\n",
        "      depth_cond = False\n",
        "\n",
        "  # Check for sample conditions\n",
        "  if min_samples_split == None:\n",
        "    sample_cond = True\n",
        "\n",
        "  else:\n",
        "    if data.shape[0] > min_samples_split:\n",
        "      sample_cond = True\n",
        "\n",
        "    else:\n",
        "      sample_cond = False\n",
        "\n",
        "  # Check for ig condition\n",
        "  if depth_cond & sample_cond:\n",
        "\n",
        "    var,val,ig,var_type = get_best_split(y, data)\n",
        "\n",
        "    # If ig condition is fulfilled, make split \n",
        "    if ig is not None and ig >= min_information_gain:\n",
        "\n",
        "      counter += 1\n",
        "\n",
        "      left,right = make_split(var, val, data,var_type)\n",
        "\n",
        "      # Instantiate sub-tree\n",
        "      split_type = \"<=\" if var_type else \"in\"\n",
        "      question =   \"{} {}  {}\".format(var,split_type,val)\n",
        "      # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" + str(val) \n",
        "      subtree = {question: []}\n",
        "\n",
        "\n",
        "      # Find answers (recursion)\n",
        "      yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
        "\n",
        "      no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
        "\n",
        "      if yes_answer == no_answer:\n",
        "        subtree = yes_answer\n",
        "\n",
        "      else:\n",
        "        subtree[question].append(yes_answer)\n",
        "        subtree[question].append(no_answer)\n",
        "\n",
        "    # If it doesn't match IG condition, make prediction\n",
        "    else:\n",
        "      pred = make_prediction(data[y],target_factor)\n",
        "      return pred\n",
        "\n",
        "   # Drop dataset if doesn't match depth or sample conditions\n",
        "  else:\n",
        "    pred = make_prediction(data[y],target_factor)\n",
        "    return pred\n",
        "\n",
        "  return subtree\n",
        "\n",
        "\n",
        "max_depth = 5\n",
        "min_samples_split = 20\n",
        "min_information_gain  = 1e-5\n",
        "\n",
        "\n",
        "decisiones = train_tree(person_df,'obese',True, max_depth,min_samples_split,min_information_gain)\n",
        "\n",
        "decisiones"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Male', 177, 117, '1')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4vaO1swLiZ"
      },
      "source": [
        "### Predecir mediante nuestro árbol de decisión\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQJ9feY8wOJC"
      },
      "source": [
        "def clasificar_datos(observacion, arbol):\n",
        "  question = list(arbol.keys())[0] \n",
        "\n",
        "\n",
        "  if question.split()[1] == '<=':\n",
        "\n",
        "    if observacion[question.split()[0]] <= float(question.split()[2]):\n",
        "      answer = arbol[question][0]\n",
        "    else:\n",
        "      answer = arbol[question][1]\n",
        "\n",
        "  else:\n",
        "\n",
        "    if observacion[question.split()[0]] in (question.split()[2]):\n",
        "      answer = arbol[question][0]\n",
        "    else:\n",
        "      answer = arbol[question][1]\n",
        "\n",
        "\n",
        "  # Si la respuesta no es un diccionario\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    residual_tree = answer\n",
        "    return clasificar_datos(observacion, answer)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EXHe7cVP-rO"
      },
      "source": [
        "### Predicción con árbol de decisión para regresión\n",
        "\n",
        "Para hacer la regresión, vamos a usar el dataset gapminder, el cual cuenta con la información del número de habitantes, PIB per Cápita de distintos países para diferentes años.\n",
        "\n",
        "Así pues, vamos a usar el algoritmo para predecir la esperanza de vida de un país teniendo en cuenta su PIB per Cápita y su población:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyRsF_S7QCZm"
      },
      "source": [
        "from gapminder import gapminder"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YHQer9KWLSL"
      },
      "source": [
        "### Predicción con árbol de decisión para clasificación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EOI8BuWPoO"
      },
      "source": [
        "wine = datasets.load_wine()"
      ],
      "execution_count": 76,
      "outputs": []
    }
  ]
}